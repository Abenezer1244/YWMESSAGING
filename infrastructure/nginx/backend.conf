# ============================================================================
# NGINX Configuration for Load Balancing
# âœ… PHASE 2: Distributes traffic across multiple backend servers
# ============================================================================
#
# This configuration:
# 1. Listens on HTTPS (port 443)
# 2. Redirects HTTP to HTTPS
# 3. Distributes traffic to 3-4 backend servers
# 4. Performs health checks
# 5. Implements rate limiting
# 6. Adds security headers
#
# File location: /etc/nginx/conf.d/backend.conf
# Reload: nginx -s reload

# ============================================================================
# UPSTREAM: Backend Servers
# ============================================================================
upstream backend_servers {
  # Load balancing algorithm
  # least_conn = Route to server with fewest active connections (recommended)
  # ip_hash = Route same IP to same server (use if stateful)
  # least_time = Route to fastest responding server
  least_conn;

  # Backend server addresses and ports
  # Add/remove servers as you scale
  # weight = relative priority (higher = more traffic)
  # max_fails = mark down after N failed checks
  # fail_timeout = how long to wait before retrying a failed server

  server backend-1.internal:3000 weight=1 max_fails=3 fail_timeout=30s;
  server backend-2.internal:3000 weight=1 max_fails=3 fail_timeout=30s;
  server backend-3.internal:3000 weight=1 max_fails=3 fail_timeout=30s;
  # server backend-4.internal:3000 weight=1 max_fails=3 fail_timeout=30s;  # Uncomment for 4th server

  # Health check configuration (nginx >= 1.12)
  # Performed on this URL every 10 seconds
  # Expected: 200 response
  check interval=10000 rise=3 fall=5 timeout=1000 type=http;
  check_http_send "GET /health HTTP/1.0\r\n\r\n";
  check_http_expect_alive http_2xx;

  # Keepalive connections for better performance
  keepalive 32;
}


# ============================================================================
# HTTP Server Block: Redirect to HTTPS
# ============================================================================
server {
  listen 80 default_server;
  listen [::]:80 default_server;
  server_name api.koinoniasms.com _;

  # Redirect all HTTP to HTTPS
  location / {
    return 301 https://$server_name$request_uri;
  }

  # Allow Let's Encrypt verification without redirect
  location /.well-known/acme-challenge/ {
    root /var/www/certbot;
  }
}


# ============================================================================
# HTTPS Server Block: Main API
# ============================================================================
server {
  listen 443 ssl http2;
  listen [::]:443 ssl http2;
  server_name api.koinoniasms.com;

  # ============================================================================
  # SSL/TLS Configuration
  # ============================================================================

  # SSL certificate paths (from Let's Encrypt)
  ssl_certificate /etc/letsencrypt/live/api.koinoniasms.com/fullchain.pem;
  ssl_certificate_key /etc/letsencrypt/live/api.koinoniasms.com/privkey.pem;

  # SSL protocol versions (disable old versions)
  ssl_protocols TLSv1.2 TLSv1.3;

  # SSL ciphers (strong only)
  ssl_ciphers 'ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384';
  ssl_prefer_server_ciphers on;

  # SSL session configuration
  ssl_session_cache shared:SSL:10m;
  ssl_session_timeout 10m;
  ssl_session_tickets off;

  # OCSP stapling (improves SSL performance)
  ssl_stapling on;
  ssl_stapling_verify on;
  resolver 8.8.8.8 8.8.4.4 valid=300s;
  resolver_timeout 5s;


  # ============================================================================
  # Security Headers
  # ============================================================================

  # HSTS: Force HTTPS for future connections
  add_header Strict-Transport-Security "max-age=31536000; includeSubDomains; preload" always;

  # Prevent clickjacking
  add_header X-Frame-Options "SAMEORIGIN" always;

  # Prevent MIME-type sniffing
  add_header X-Content-Type-Options "nosniff" always;

  # Enable XSS protection in older browsers
  add_header X-XSS-Protection "1; mode=block" always;

  # Content Security Policy (strict)
  add_header Content-Security-Policy "default-src 'self'; script-src 'self'; style-src 'self' 'unsafe-inline'; img-src 'self' data: https:; font-src 'self'; connect-src 'self'; frame-ancestors 'none';" always;

  # Referrer policy
  add_header Referrer-Policy "strict-origin-when-cross-origin" always;


  # ============================================================================
  # Logging
  # ============================================================================

  # Access log with detailed format
  access_log /var/log/nginx/backend_access.log combined buffer=32k flush=5s;

  # Error log
  error_log /var/log/nginx/backend_error.log warn;


  # ============================================================================
  # Rate Limiting
  # ============================================================================

  # Define rate limit zones
  limit_req_zone $binary_remote_addr zone=auth_limit:10m rate=10r/s;
  limit_req_zone $binary_remote_addr zone=api_limit:10m rate=100r/s;
  limit_req_zone $binary_remote_addr zone=webhook_limit:10m rate=50r/s;

  # Auth endpoints: 10 req/s (strict to prevent brute force)
  location ~^/api/(auth|login|register|forgot-password|reset-password) {
    limit_req zone=auth_limit burst=5 nodelay;

    # Pass to upstream
    proxy_pass http://backend_servers;
    proxy_http_version 1.1;

    # Proxy headers
    proxy_set_header Host $host;
    proxy_set_header X-Real-IP $remote_addr;
    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    proxy_set_header X-Forwarded-Proto $scheme;
    proxy_set_header Connection "";

    # Timeouts
    proxy_connect_timeout 30s;
    proxy_send_timeout 30s;
    proxy_read_timeout 30s;
  }

  # Webhook endpoints: moderate rate limit
  location ^/api/webhooks/ {
    limit_req zone=webhook_limit burst=20 nodelay;

    proxy_pass http://backend_servers;
    proxy_http_version 1.1;
    proxy_set_header Host $host;
    proxy_set_header X-Real-IP $remote_addr;
    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    proxy_set_header X-Forwarded-Proto $scheme;
    proxy_set_header Connection "";

    proxy_connect_timeout 60s;
    proxy_send_timeout 60s;
    proxy_read_timeout 60s;
  }

  # General API: 100 req/s (generous for normal traffic)
  location /api/ {
    limit_req zone=api_limit burst=20 nodelay;

    proxy_pass http://backend_servers;
    proxy_http_version 1.1;

    # Proxy headers
    proxy_set_header Host $host;
    proxy_set_header X-Real-IP $remote_addr;
    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    proxy_set_header X-Forwarded-Proto $scheme;
    proxy_set_header Connection "";

    # WebSocket support (for Socket.IO chat)
    proxy_set_header Upgrade $http_upgrade;
    proxy_set_header Connection "upgrade";

    # Timeouts for general API
    proxy_connect_timeout 30s;
    proxy_send_timeout 30s;
    proxy_read_timeout 30s;

    # Buffering
    proxy_buffering on;
    proxy_buffer_size 4k;
    proxy_buffers 8 4k;
  }

  # Health check endpoint: no rate limit (used by monitoring)
  location /health {
    access_log off;  # Don't log health checks

    proxy_pass http://backend_servers;
    proxy_http_version 1.1;
    proxy_set_header Host $host;
    proxy_set_header Connection "";

    # Fast timeout for health checks
    proxy_connect_timeout 5s;
    proxy_read_timeout 5s;
  }

  # Detailed health endpoint: no rate limit
  location /health/detailed {
    access_log off;

    proxy_pass http://backend_servers;
    proxy_http_version 1.1;
    proxy_set_header Host $host;
    proxy_set_header Connection "";

    proxy_connect_timeout 5s;
    proxy_read_timeout 5s;
  }

  # Catch-all: Default to API limit
  location / {
    limit_req zone=api_limit burst=20 nodelay;

    proxy_pass http://backend_servers;
    proxy_http_version 1.1;
    proxy_set_header Host $host;
    proxy_set_header X-Real-IP $remote_addr;
    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    proxy_set_header X-Forwarded-Proto $scheme;
    proxy_set_header Connection "";

    proxy_connect_timeout 30s;
    proxy_send_timeout 30s;
    proxy_read_timeout 30s;
  }
}


# ============================================================================
# Monitoring/Status Server (Internal Only)
# ============================================================================
# Run on port 8080, restricted to private network
# Access: curl http://localhost:8080/nginx_status

server {
  listen 8080;
  listen [::]:8080;
  server_name localhost;

  # Restrict access to private IPs
  location /nginx_status {
    stub_status on;
    access_log off;
    allow 127.0.0.1;           # localhost
    allow ::1;                 # IPv6 localhost
    allow 10.0.0.0/8;         # Private network
    allow 172.16.0.0/12;      # Private network
    allow 192.168.0.0/16;     # Private network
    deny all;
  }

  # Health status endpoint
  location /health {
    access_log off;
    return 200 "NGINX is healthy\n";
    add_header Content-Type text/plain;
  }
}


# ============================================================================
# NOTES FOR PRODUCTION
# ============================================================================
#
# 1. Deployment:
#    - Save to /etc/nginx/conf.d/backend.conf
#    - Run: nginx -t (test syntax)
#    - Run: systemctl restart nginx (apply changes)
#
# 2. SSL Certificate:
#    - Use Let's Encrypt certbot
#    - Run: certbot certonly --standalone -d api.koinoniasms.com
#    - Set up auto-renewal: systemctl enable certbot.timer
#
# 3. Backend Server Discovery:
#    - Update backend-1/2/3 hostnames
#    - Or use IP addresses if DNS not available
#    - Test: curl http://backend-1.internal:3000/health
#
# 4. Health Checks:
#    - Ensure /health endpoint exists on backends
#    - NGINX checks every 10 seconds (interval=10000ms)
#    - 3 successful checks = server UP
#    - 5 failed checks = server DOWN
#
# 5. Monitoring:
#    - Check NGINX status: curl http://localhost:8080/nginx_status
#    - Monitor logs: tail -f /var/log/nginx/backend_access.log
#    - Monitor errors: tail -f /var/log/nginx/backend_error.log
#
# 6. Scaling:
#    - Add more backend servers by adding lines to upstream block
#    - Uncomment backend-4 line when adding 4th server
#    - No NGINX restart needed if using dynamic upstream
#
# 7. Performance Tuning:
#    - Increase worker_processes in main nginx.conf
#    - Increase worker_connections if high concurrency
#    - Monitor connection distribution with /nginx_status
